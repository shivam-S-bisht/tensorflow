{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<TensorSliceDataset shapes: (), types: tf.int32>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#the following dataset is a scalar\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([8,3,0,8,2,1])\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8\n3\n0\n8\n2\n1\n"
    }
   ],
   "source": [
    "for element in dataset:\n",
    "    print(element.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "22"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#reduce the elemnts to produce a single digit\n",
    "dataset.reduce(0, lambda state, value: state + value).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TensorSpec(shape=(10,), dtype=tf.float32, name=None)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n",
    "dataset1.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices((tf.random.uniform([4]), tf.random.uniform([4, 100], maxval = 100, dtype = tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataset2.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n (TensorSpec(shape=(), dtype=tf.float32, name=None),\n  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "dataset3.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SparseTensorSpec(TensorShape([3, 4]), tf.int32)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices = [[0, 0], [1, 2]], values = [1, 2], dense_shape = [3, 4]))\n",
    "dataset4.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[array([0, 1, 2, 3], dtype=int64), array([ 0, -1, -2, -3], dtype=int64)]\n[array([4, 5, 6, 7], dtype=int64), array([-4, -5, -6, -7], dtype=int64)]\n[array([ 8,  9, 10, 11], dtype=int64), array([ -8,  -9, -10, -11], dtype=int64)]\n[array([12, 13, 14, 15], dtype=int64), array([-12, -13, -14, -15], dtype=int64)]\n[array([16, 17, 18, 19], dtype=int64), array([-16, -17, -18, -19], dtype=int64)]\n"
    }
   ],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "it = iter(batched_dataset)\n",
    "for batch in batched_dataset.take(5):\n",
    "    print([arr.numpy() for arr in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<BatchDataset shapes: ((None,), (None,)), types: (tf.int64, tf.int64)>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dataset = dataset.batch(7, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<BatchDataset shapes: ((7,), (7,)), types: (tf.int64, tf.int64)>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0 0 0]\n [1 0 0]\n [2 2 0]\n [3 3 3]]\n\n[[4 4 4 4 0 0 0]\n [5 5 5 5 5 0 0]\n [6 6 6 6 6 6 0]\n [7 7 7 7 7 7 7]]\n\n[[ 8  8  8  8  8  8  8  8  0  0  0]\n [ 9  9  9  9  9  9  9  9  9  0  0]\n [10 10 10 10 10 10 10 10 10 10  0]\n [11 11 11 11 11 11 11 11 11 11 11]]\n\n[[12 12 12 12 12 12 12 12 12 12 12 12  0  0  0]\n [13 13 13 13 13 13 13 13 13 13 13 13 13  0  0]\n [14 14 14 14 14 14 14 14 14 14 14 14 14 14  0]\n [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]]\n\n[[16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16  0  0  0]\n [17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17  0  0]\n [18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18  0]\n [19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19]]\n\n"
    }
   ],
   "source": [
    "#for the dataset of different dimentions\n",
    "\n",
    "dataset = tf.data.Dataset.range(100)\n",
    "\n",
    "\n",
    "dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\n",
    "\n",
    "#padded batch pad the values if there are not in the dataset with 0s\n",
    "dataset = dataset.padded_batch(4, padded_shapes = (None, ))\n",
    "\n",
    "for batch in dataset.take(5):\n",
    "    print(batch.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high level apis\n",
    "\n",
    "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
    "images, labels = train\n",
    "images = images/255.0\n",
    "labels = labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(10, activation = 'softmax')])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 1875 steps\nEpoch 1/2\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.5967 - accuracy: 0.7988\nEpoch 2/2\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.4620 - accuracy: 0.8433\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x176b6a4d550>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.fit(fmnist_train_ds, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 20 steps\nEpoch 1/2\n20/20 [==============================] - 1s 26ms/step - loss: 0.3933 - accuracy: 0.8594\nEpoch 2/2\n20/20 [==============================] - 0s 7ms/step - loss: 0.4571 - accuracy: 0.8438\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x176b68b7d30>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#passing an infinite dataset by passing repeat with no arguments by telling ow much steps of datasets we need to train\n",
    "model.fit(fmnist_train_ds.repeat(), epochs = 2, steps_per_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4532 - accuracy: 0.8439\n0.4532144069433212 0.84386665\n"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(fmnist_train_ds)\n",
    "print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "20/20 [==============================] - 0s 12ms/step - loss: 0.4080 - accuracy: 0.8734\n"
    }
   ],
   "source": [
    "#if the dataset is very big we need to pass the steps arguments\n",
    "\n",
    "loss, accuracy = model.evaluate(fmnist_train_ds.repeat(), steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[3.2264085e-09 3.9397703e-09 1.1981076e-07 ... 3.5013054e-03\n  7.6725380e-05 9.9420977e-01]\n [9.5420969e-01 7.9144706e-07 4.3898327e-03 ... 9.8071334e-13\n  3.3311949e-06 3.6977407e-10]\n [2.2665569e-01 1.2841074e-01 7.4463524e-02 ... 5.7009218e-04\n  2.9183154e-03 4.9994915e-04]\n ...\n [7.8410165e-05 5.1918214e-05 2.6010606e-01 ... 2.9603284e-10\n  2.1594396e-04 4.8054010e-09]\n [7.5236679e-04 9.7521712e-05 7.7512777e-01 ... 1.3478642e-09\n  1.3347052e-03 1.1039691e-08]\n [4.3377094e-02 1.0681308e-03 4.4301962e-03 ... 2.0003069e-06\n  5.7492599e-02 1.8313496e-08]]\n"
    }
   ],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices(images).batch(32)\n",
    "results = model.predict(test_ds, steps = 20)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<BatchDataset shapes: (None, 28, 28), types: tf.float64>\n<BatchDataset shapes: ((None, 28, 28), (None,)), types: (tf.float64, tf.int32)>\n"
    }
   ],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices(images).batch(32)\n",
    "print(test_ds)\n",
    "print(fmnist_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bit59cde4ac88ac46128fa55d3d84c36661",
   "display_name": "Python 3.7.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}